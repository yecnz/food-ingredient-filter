# food-filter/ocr.py (Python ìŠ¤í¬ë¦½íŠ¸ - Node.js ì—°ë™ìš©)

import cv2
import pytesseract
import os
import re
import sys # ì¸ì ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€
import json # JSON ì¶œë ¥ì„ ìœ„í•´ ì¶”ê°€
from Levenshtein import distance 

# --- [ì„¤ì • 1] Tesseract ê²½ë¡œ ---
pytesseract.pytesseract.tesseract_cmd = "/opt/homebrew/bin/tesseract" # âš ï¸ ì‚¬ìš©ì ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •
# pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe" # (Windows ì˜ˆì‹œ)

# --- [ì„¤ì • 2] í´ë” ì„¤ì • ---
BASE_DIR = os.path.expanduser("~/Desktop/project/food-filter") # âš ï¸ ì‚¬ìš©ì ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •
IMAGE_DIR = os.path.join(BASE_DIR, "image")
RESULT_DIR = os.path.join(BASE_DIR, "result") 

os.makedirs(RESULT_DIR, exist_ok=True)
os.makedirs(IMAGE_DIR, exist_ok=True) 

# --- [ì„¤ì • 3] OCR ì„¤ì • ---
OCR_CONFIG = '--oem 3 --psm 3' 

# ===== 1. ì„±ë¶„ ì‚¬ì „ (ë°ì´í„°ë² ì´ìŠ¤) =====
# Node.jsì—ì„œ ì „ë‹¬ë°›ì€ user_settingsë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•„í„°ë§í•˜ëŠ” DB
ingredient_dict = {
    # ì‹ì•½ì²˜ ê³ ì‹œ 19ì¢… + í˜¸ë‘, ì£ (ì‚¬ìš©ì ì½”ë“œ ê¸°ë°˜)
    "ì•Œë ˆë¥´ê²": [
        "ìš°ìœ ", "ë‹¬ê±€", "ê³„ë€", "ë°€", "ë©”ë°€", "ë•…ì½©", "ëŒ€ë‘", "ì£", "ìƒˆìš°", "ê²Œ",
        "ì˜¤ì§•ì–´", "ê³ ë“±ì–´", "ì¡°ê°œë¥˜", "ë‹­ê³ ê¸°", "ì‡ ê³ ê¸°", "ë¼ì§€ê³ ê¸°", "ë³µìˆ­ì•„",
        "í† ë§ˆí† ", "ì•„í™©ì‚°ë¥˜", "í˜¸ë‘"
    ],

    "ë¹„ê±´X": [
        "ê¿€", "ì ¤ë¼í‹´", "ì¹´ì œì¸", "ë²„í„°", "ìœ ì²­", "ë‚œë°±", "ë‚œí™©", "ë½í† ìŠ¤",
        "ì½”ì¹˜ë‹", "ì¹´ë¯¼", 
        "ì‰˜ë½", "L-ì‹œìŠ¤í…Œì¸", "ë¹„íƒ€ë¯¼ D3",
        "ë™ë¬¼ì„±ìœ ì§€", "ë™ë¬¼ì„±ì§€ë°©", "ëˆì§€", "ìš°ì§€", "ì½œë¼ê²"      
        ],

    "ê¸°íƒ€ê¸°í”¼": [
        "MSG", "íŠ¸ëœìŠ¤ì§€ë°©", "ì‚¬ì¹´ë¦°", "ì•„ìŠ¤íŒŒíƒ", "ì•„ì„¸ì„¤íŒœì¹¼ë¥¨", "ìˆ˜í¬ë„ë¡œìŠ¤"
    ]
}

# ===== 2. ë™ì˜ì–´/í™•ì¥ ë§¤í•‘ =====
synonyms = {
    "ì „ì§€ë¶„ìœ ": "ìš°ìœ ", "íƒˆì§€ë¶„ìœ ": "ìš°ìœ ", "ë¶„ìœ ": "ìš°ìœ ", "ì¹´ì œì¸": "ìš°ìœ ",
    "ë ˆì‹œí‹´": "ëŒ€ë‘", "ì½©ê¸°ë¦„": "ëŒ€ë‘", "ë‘ìœ ": "ëŒ€ë‘", "ë‹¬ê±€": "ê³„ë€",
    "ë‚œë°±": "ê³„ë€", "ë‚œí™©": "ê³„ë€", "ë‹­ê°€ìŠ´ì‚´": "ë‹­ê³ ê¸°"
}


# --- [í•¨ìˆ˜] OCR ì „ì²˜ë¦¬ ë° êµì • ë¡œì§ ---
def preprocess_for_ocr(image):
    """OCR ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    binary = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 8)
    return binary

# (ê¸°ì¡´ ocr.pyì˜ correct_word_with_dbì™€ postprocess_text í•¨ìˆ˜ê°€ í•„ìš”í•˜ë‚˜, 
#  ì‹œê°„ ì ˆì•½ì„ ìœ„í•´ ì—¬ê¸°ì„œëŠ” í•„í„°ë§ ë¡œì§ì— ì§‘ì¤‘í•˜ê³  OCR êµì •ì€ ìƒëµí•©ë‹ˆë‹¤.)


# --- [í•¨ìˆ˜] ì„±ë¶„ ë¶„ë¦¬ ë° ë§¤ì¹­ ë¡œì§ ---
def parse_ingredients(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ê´„í˜¸ ì•ˆíŒì˜ ì„±ë¶„ì„ ëª¨ë‘ ë¶„ë¦¬í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    inner_texts = re.findall(r"\((.*?)\)", text)
    parsed = []
    for inner in inner_texts:
        inner_parts = [i.strip() for i in inner.split(",")]
        parsed.extend(inner_parts)

    no_parentheses_text = re.sub(r"\s*\(.*?\)", "", text)
    outer_parts = [p.strip() for p in no_parentheses_text.split(",") if p.strip()]

    return outer_parts + parsed

def match_ingredients(parsed_ingredients, db, synonyms_map, user):
    """ì‚¬ìš©ì ì„¤ì •(user)ì— ë”°ë¼ ì„±ë¶„ì„ ê²½ê³ /ì£¼ì˜/ì•ˆì „ìœ¼ë¡œ ë¶„ë¥˜"""
    results = {
        "ê²½ê³ ": set(),
        "ì£¼ì˜": set(),
        "ì•ˆì „": set()
    }
    matched_original_ingredients = set()

    for ing in parsed_ingredients:
        if ing in matched_original_ingredients or not ing:
            continue

        check_value = synonyms_map.get(ing, ing)
        found = False

        # 1. [ê²½ê³ ] ì•Œë ˆë¥´ê² ê²€ì‚¬ (ì‚¬ìš©ì ì„¤ì • ê¸°ë°˜)
        for allergen_item in db["ì•Œë ˆë¥´ê²"]:
            if allergen_item in check_value and allergen_item in user["ì•Œë ˆë¥´ê¸°"]:
                results["ê²½ê³ "].add(f"{ing} (í¬í•¨ëœ ì•Œë ˆë¥´ê²: {allergen_item})")
                matched_original_ingredients.add(ing)
                found = True
                break
        if found: continue

        # 2. [ì£¼ì˜] ë¹„ê±´ ê²€ì‚¬ (ì‚¬ìš©ì ì„¤ì • ê¸°ë°˜)
        if user["ë¹„ê±´"]:
            for vegan_item in db["ë¹„ê±´X"]:
                if vegan_item in check_value:
                    results["ì£¼ì˜"].add(f"{ing} (ë¹„ê±´X ì„±ë¶„: {vegan_item})")
                    matched_original_ingredients.add(ing)
                    found = True
                    break
        if found: continue

        # 3. [ì£¼ì˜] ê¸°íƒ€ ê¸°í”¼ ì„±ë¶„ ê²€ì‚¬ (ì‚¬ìš©ì ì„¤ì • ê¸°ë°˜)
        for etc_item in db["ê¸°íƒ€ê¸°í”¼"]:
            if etc_item in check_value and etc_item in user["ê¸°íƒ€ê¸°í”¼"]:
                results["ì£¼ì˜"].add(f"{ing} (ê¸°í”¼ ì„±ë¶„: {etc_item})")
                matched_original_ingredients.add(ing)
                found = True
                break

        # 4. [ì•ˆì „] ì–´ë””ì—ë„ í•´ë‹¹ë˜ì§€ ì•Šì€ ê²½ìš°
        if not found:
            results["ì•ˆì „"].add(ing)
            matched_original_ingredients.add(ing)

    # setì„ listë¡œ ë³€í™˜í•˜ê³  ìµœì¢… ê²°ê³¼ë¥¼ ì •ë¦¬
    final_results = []
    if results["ê²½ê³ "]:
        final_results.append({
            "status": "danger",
            "message": f"ğŸš¨ ê²½ê³ : {', '.join(results['ê²½ê³ '])}"
        })
    if results["ì£¼ì˜"]:
        final_results.append({
            "status": "warning",
            "message": f"âš ï¸ ì£¼ì˜: {', '.join(results['ì£¼ì˜'])}"
        })
    # ì•ˆì „ ì„±ë¶„ì€ ì „ì²´ ì„±ë¶„ ëª©ë¡ì´ ë„ˆë¬´ ê¸¸ì–´ì§€ë¯€ë¡œ, ê²½ê³ /ì£¼ì˜ê°€ ì—†ê±°ë‚˜ ì†Œìˆ˜ì¸ ê²½ìš°ì—ë§Œ ìš”ì•½ í‘œì‹œ
    if not final_results or len(final_results) < 2:
        safe_count = len(results["ì•ˆì „"])
        final_results.append({
            "status": "safe",
            "message": f"âœ… ì•ˆì „: ìœ„í—˜ ì„±ë¶„ ë¯¸ê²€ì¶œ. ({safe_count}ê°€ì§€ ì¼ë°˜ ì„±ë¶„)"
        })

    return final_results


# --- [ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜] ---
def main_analysis(user_settings_json, image_filename):
    """Node.jsë¡œë¶€í„° ì¸ìë¥¼ ë°›ì•„ OCRì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì¶œë ¥"""
    try:
        # 1. ì‚¬ìš©ì ì„¤ì • íŒŒì‹±
        user_settings = json.loads(user_settings_json)
        # print(f"ì‚¬ìš©ì ì„¤ì • ìˆ˜ì‹ : {user_settings}", file=sys.stderr) # ë””ë²„ê¹…ìš© (stderrë¡œ ì¶œë ¥)

        # 2. ì´ë¯¸ì§€ ë¡œë“œ ë° OCR ì‹¤í–‰
        full_path = os.path.join(IMAGE_DIR, image_filename)
        img_original = cv2.imread(full_path)
        
        if img_original is None:
            raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {full_path}")
            
        processed_image = preprocess_for_ocr(img_original)
        # Tesseract ì‹¤í–‰
        raw_text = pytesseract.image_to_string(processed_image, lang="kor", config=OCR_CONFIG)
        
        # 3. OCR ê²°ê³¼ í…ìŠ¤íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (ì„ íƒ ì‚¬í•­)
        base_name = os.path.splitext(image_filename)[0]
        output_filename = f"{base_name}_ocr_result.txt"
        output_path = os.path.join(RESULT_DIR, output_filename)
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(raw_text)
        # print(f"OCR ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_filename}", file=sys.stderr)

        # 4. ì„±ë¶„ ë¶„ì„ ë° ë§¤ì¹­ (í•µì‹¬)
        ingredients = parse_ingredients(raw_text)
        analysis_results = match_ingredients(ingredients, ingredient_dict, synonyms, user_settings)
        
        # 5. ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ í‘œì¤€ ì¶œë ¥ (Node.jsê°€ ë°›ìŒ)
        # sys.stdout.write() ëŒ€ì‹  print()ë¥¼ ì‚¬ìš©í•´ë„ ë©ë‹ˆë‹¤.
        print(json.dumps(analysis_results, ensure_ascii=False))

    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
        error_message = {"error": True, "message": str(e), "detail": "Python script failed"}
        print(json.dumps([{"status": "danger", "message": f"ë¶„ì„ ì‹¤íŒ¨ ì˜¤ë¥˜: {str(e)}"}], ensure_ascii=False))
        sys.exit(1)


if __name__ == "__main__":
    if len(sys.argv) < 3:
        # Node.jsì—ì„œ ì¸ìê°€ ì¶©ë¶„íˆ ì „ë‹¬ë˜ì§€ ì•Šì€ ê²½ìš°
        print(json.dumps([{"status": "danger", "message": "ì‹œìŠ¤í…œ ì˜¤ë¥˜: ì‚¬ìš©ì ì„¤ì • ë° íŒŒì¼ëª…ì´ ì „ë‹¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}]), ensure_ascii=False)
        sys.exit(1)
        
    # sys.argv[1]: ì‚¬ìš©ì ì„¤ì • JSON ë¬¸ìì—´
    # sys.argv[2]: ì´ë¯¸ì§€ íŒŒì¼ëª…
    main_analysis(sys.argv[1], sys.argv[2])